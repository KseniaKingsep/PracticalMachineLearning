
#Prediction Assignment Writeup - Excersise Manner Modeling

##Introduction  

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 
The goal of this project is to predict the manner in which people did the exercise. We will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to build a prediction model.
More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

##Data Processing
We prepare workspace (load packages), download and read in the datasets.
```{r, results="hide", message=FALSE}
# Load packages
library(caret)
library(randomForest)
# Create data directory if necessary
if (!dir.exists("./data")) {
  dir.create("./data")
}
# Download and read in the datasets
fileUrl1="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
fileUrl2="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileUrl1, destfile="./data/pml-training.csv")
download.file(fileUrl2, destfile="./data/pml-testing.csv")
training <- read.table("./data/pml-training.csv", sep = ",", header = TRUE, na.strings = c("NA", ""))
testing <- read.table("./data/pml-testing.csv", sep = ",", header = TRUE, na.strings = c("NA", ""))
```
Preprocess data a bit: remove near zero variance variables, row numbers, names and timestamps, variables with NAs. 
```{r}
myTraining <- training[,-nearZeroVar(training)]
myTraining <- myTraining[,-c(1,2,3,4,5,6,7)]
myTraining <- myTraining[, colSums(is.na(myTraining)) == 0]
```
Create validation and training sets:
```{r }
set.seed(11114)
inTrain <- createDataPartition(y=training$classe, p=0.7, list=FALSE)
myTraining <- myTraining[inTrain,]
myValidation <- myTraining[-inTrain,]
```

##Model Building

####Model 1 - RandomForest  
We use cross validation (`method = "cv"`) for resampling during modeling, and `number` parameter sets the number of subsamples to take. 
``` {r}
set.seed(999)
rfControl <- trainControl(method="cv", number=3, verboseIter=FALSE)
rfModel <- train(classe ~ ., data=myTraining, method="rf", trControl = rfControl)
predictionValidation <- predict(rfModel, myValidation)
```
To evaluate the model we use the confusionMatrix method. We will focus on accuracy, sensitivity and specificity metrics. 
```{r, results="markup"}
confusionMatrix(predictionValidation, myValidation$classe)$overall["Accuracy"]
confusionMatrix(predictionValidation, myValidation$classe)$table
```
Confusion matrix shows accuracy, sensitivity and specificity to be exactly 1. So this prediction model is showing really great results. 

####Model 2 - Boosting
```{r, results="hide", message=FALSE}
set.seed(777)
boostControl <- trainControl(method="cv", number=3, verboseIter=FALSE)
boostModel <- train(classe ~ ., data=myTraining, method="gbm", trControl = boostControl)
predictionValidation2 <- predict(boostModel, myValidation)
```
To evaluate the model we use the confusionMatrix method. We will focus on accuracy, sensitivity and specificity metrics. 
```{r, results="markup"}
confusionMatrix(predictionValidation2, myValidation$classe)$overall["Accuracy"]
confusionMatrix(predictionValidation2, myValidation$classe)$table
```
Boosting shows Accuracy of 0.9746, which is quite good, but still less than `rf` method. 

##Prediction on testing data
We use randomFprest model as the most accurate to predict classe for the testing data.
```{r, results="markup"}
predict(rfModel, testing)
```
This answers show to be 100% correct on the Quiz. 

#Conclusion 

Random forest model appears to be best fitting for these data. Boosting shows less accuracy on the validation set and also on testing sample.
